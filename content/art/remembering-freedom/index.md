---
title: Remembering Freedom
subtitle: An essay on the first 558 years of the internet.
medium: essay
authors: John McNeil
license: CC BY-SA 4.0
lang: [original, en, de]
alt: Drawing of a laptop, whose display shows the title Remembering Freedom
de:
    medium: Essay
    subtitle: Ein Essay über die ersten 558 Jahre des Internets.
    alt: Zeichnung eines Laptops, dessen Bildschirm den Titel Remembering Freedom zeigt
id: remembering-freedom
---

Cover image by [Kat Aymeloglu](https://www.kataymeloglu.com).

## Downloads

- [PDF](/{{ id }}/Remembering%20Freedom.pdf)
- [EPUB](/{{ id }}/Remembering%20Freedom.epub)

## Contents
[Hello from Nowhere](#hello-from-nowhere)

[The Early Internet](#the-early-internet)

[2050-2100](#2050-2100)

[2100s](#2100s)

[2200s](#2200s)

[2300s](#2300s)

[2400s](#2400s)

[2532](#2532)

[Bibliography](#bibliography)

## Text

I’m from the future and your internet is <em>awful</em>.

It’s so full of lies, scams, abuse, and manipulation that it’s hard to know whether to pity the people who lack access. I’d like to assume that you’re all doing your best, but I’m not here to insult you.

I’m here to give you some good news. The internet is going to get better. A lot better, in ways you can hardly imagine.
I know this because, as I said – from the future! I’m a historian from the year 2532, contributing to this conference by describing the evolution of the internet over its first 558 years, and I’ll get to that. But first of all, why was it so bad after a half century?

Essentially, I submit, because it was still so new and unnatural. By 2024, the internet and the web had been ubiquitous in some countries for only a generation or two, and in other countries for much less time than that. No one was prepared for its vast social implications, certainly not its inventors, and not even the most astute people alive in the mid-twentieth century.

Consider the political theorist Hannah Arendt. In Origins of Totalitarianism, she described some of the most frightening aspects of authoritarian governments, for example, the way the czarist secret police had tracked their suspects. What they did, according to Arendt, was write each suspect’s name on a card and then draw a red circle around the name. Then they wrote more names down on the card and drew circles around them too, using various colors to represent different areas of the suspect’s life. But the czarist secret police didn’t stop there. They also drew lines between the circles.

Staggered by the implications of such a technique, Arendt mused that with a gigantic sheet of paper, the secret police could map out all the relationships of an entire society! This was their “Utopian goal.” A dark vision, to be sure, but Arendt, in her 1951 book, brightened things slightly by saying that its “technical execution is bound to be somewhat difficult.”[^1]

[^1]: Hannah Arendt, <em>The Origins of Totalitarianism</em> (New York: Harcourt, Inc., 1951, 1976), 433–34.

A mere few decades after those words were published, its technical execution would hardly be difficult. By the 2010s, billions of people had given the data for such a map to the intelligence services of the world by sending things called friend requests on something called Facebook and similar platforms. Social media had realized the secret police’s Utopia, not because suddenly no one cared about privacy anymore, but because the internet was still something new under the sun.

What fascinates me is how the internet evolved after that, eventually contributing to major social transformations for the good, becoming a Utopia not for totalitarians, but for humanity: for a just and humane world. That is what this essay will explore.

### Hello from Nowhere
Roughly a thousand years ago, in 1517, Sir Thomas More published the book Utopia, coining a word that literally means “no place,” and launching the modern genre of writing about an imagined, desired society. The world of my contemporaries in the year 2532 is far from what More imagined, but it is Utopian according to our notions. Everyone can connect with everyone else without secret police mapping them, whether with note cards or by any other means. It is the kind of Utopia that the early 20th century writer Marie Louise Berner would have called anti-authoritarian, by which she meant one which “points to an ideal life without becoming a plan.”[^2] We have social and economic equality, human rights, global peace, well-regulated tech companies that do not exert monopoly power, and privacy laws that protect users of the world wide web, which is decentralized and truly open to all through open standards and free software.

[^2]: Marie Louise Berneri, <em>Journey Through Utopia</em> (Oakland: PM Press, 1950, 2019), 8. 

My task is to explain how the internet got from being so terrible during its first half century to being quite Utopian now. How did the web grow out of its dreadful adolescence in the 2020s, when billions of people lacked access, and even for those who had it, much of the content was confined inside walled gardens of giant tech companies perpetrating surveillance capitalism? How did it become the liberated internet of my day?

### The Early Internet
When More published Utopia, few people could have read it, even though movable type had existed for about seventy years, and even though More wrote in Latin, the lingua franca of educated people in his time. Literacy was confined to a tiny elite. The book gained its reputation as a classic during a century when the vast majority of his compatriots could not understand a page of it.

Roughly five hundred years later, in the 1970s, the protocols that enable computers to talk to each other on a network were developed in a similar environment of widespread ignorance about what they were, how they worked, and that they even existed. That was the decade when United States federal contractors solved some engineering problems in an effort that was later called the invention of the internet. But by the year 1974, arguably the first year of the internet, most of what are still considered the consensus good ideas of computer science were already invented.[^3] Most people who grew up in the 1970s, however, would have known nothing about this, and decades later, when computers became mandatory parts of work and life, would consider them strange new things. Later on, people much younger than the TCP/IP protocol thought that the internet began in the 1990s. Is it surprising they ran into problems?

[^3]: “Good Ideas in Computer Science,” April 21, 2024, https://danielchasehooper.com/posts/good-ideas-in-cs/.

As the web gained mass adoption in the 1990s, it sparked a great deal of optimism. It would democratize the world, since dictators would no longer be able to hide their atrocities. Now that everyone could email everyone else, people would put aside their ancient hatreds. In the United States during the 1990s, the internet was known as “the information superhighway,” a glamorous name that probably came from the artist and visionary Nam June Paik.[^4] As the connectivity he had envisioned became real, however, Paik used a scarier metaphor: “we’re in a boat in the ocean, and we don’t know where the shore is.”[^5]

[^4]: “Electronic Superhighway: Continental U.S., Alaska, Hawaii | Smithsonian American Art Museum,” accessed September 2, 2532, https://americanart.si.edu/artwork/electronic-superhighway-continental-us-alaska-hawaii-71478.
[^5]: Nam June Paik: Moon is the Oldest TV. (2003). [Film]. Directed by Amanda Kim. Greenwich Entertainment. 1:17.

 It would be hard to summarize better the state of the early internet generations. They were lost at sea, adrift. How ill equipped they were to navigate the vast reaches of communication suddenly available to them. The first fifty years of personal computers and the internet being widespread in some parts of the world were brilliantly innovative but also full of infinite distractions and scams, and predators and profiteers large and small. It took time to build the institutions that could serve as lighthouses for those lost in the digital oceans.
 
By the 2020s, the state of affairs was roughly this: internet connection was ubiquitous in northern Europe, the United States, Canada, and parts of East Asia, most of all South Korea. A third of all the people in the world, however, still had no internet access. In countries of sub-Saharan Africa, that ratio was roughly the opposite: super-majorities lacked access. In North Korea, no one was online except state-sponsored hackers.[^6]

[^6]: “Internet Use in 2024,” DataReportal – Global Digital Insights, January 31, 2024, https://datareportal.com/reports/digital-2024-deep-dive-the-state-of-internet-adoption.

For the fortunate ones who were online, internet freedom had been in decline for over a decade.[^7] Political censorship was perhaps most extreme in China, but many authoritarian states around the world routinely blocked websites, targeted journalists through online surveillance, and deployed artificial intelligence to spread disinformation during elections.

[^7]: “Freedom on the Net,” Freedom House, accessed September 2, 2532, https://freedomhouse.org/report/freedom-net.

The private sector internet was dominated by a few big for-profit tech companies based in the United States. Much of the globe’s web traffic stayed inside their walled gardens, and they ransacked their users’ privacy and sold their attention to advertisers in a system that was already named “surveillance capitalism.”[^8] The technology of that time could be especially frustrating to people with disabilities, which means almost everyone, at some point in their lives. Most websites did not even meet the basic accessibility standards of the time: things like indicating what language a website uses, or making it fully operable by keyboards and screen readers.[^9]

[^8]: Shoshana Zuboff, <em>The Age of Surveillance Capitalism: The Fight for a Human Future at the New Frontier of Power</em> (New York: PublicAffairs, 2019).

[^9]: “WebAIM: The WebAIM Million - The 2024 Report on the Accessibility of the Top 1,000,000 Home Pages,” accessed September 2, 2532, https://webaim.org/projects/million/.

All this coincided with the disorganized state of Utopian thinking in the early 21st century. Various strands of it existed. There were notions like Techno-gaianism, accelerationism, and half-joking talk of Fully Automated Luxury Communism. And yet, a 2019 scholarly essay summarizing Utopian writing since 1948[^10] did not even mention one of the most ambitious bodies of Utopian thinking at the time: the Real Utopias Project.[^11] It was the brainchild a scholar whose 2019 book How to be an Anticapitalist in the 21st Century now reads like a quite accurate guide to the slow demise of capitalism over the next two hundred years (but I’m getting ahead of myself).

[^10]: Rhiannon Firth, “Afterword,” in <em>Journey Through Utopia</em> (Oakland: PM Press, 2019), 331–92.

[^11]: “The Real Utopias Project,” https://www.realutopiasproject.com/.


### 2050-2100
Space does not permit an account all the major events of the early 21st century, from the 2020s pandemics to the 2030s floods that led to the construction of seawalls in Manhattan, London, and some other coastal cities that could afford them, to the ransomware attacks on Taiwan in 2047, to the unwelcome return every few years of the Windows blue screen of death. Varied as they were, these crises all had at least one thing in common: they militated for a larger and more interventionist role of government. The neoliberalism of the turn of the millennium was wholly inadequate. Only governments, and international cooperation between governments, could cope with these global crises. It’s understandable, then, that by the 2050s, the same industrial policies and international institutions that had kept climate change within survivable limits began to be applied to shaping and regulating the internet.[^12]

[^12]: One example was a U.N. agency known as the Ministry of the Future, in an homage to Kim Stanley Robinson’s 2019 novel of the same name.

During the first half of the 21st century, progress in internet governance had been made on many fronts, thanks to the work of activist and experts around the world, but it was not until the 2050s that something like a global regime for managing the internet came into existence. The reforms that followed were not new ideas. As the author William Gibson is believed to have said, “the future is already here – it’s just not evenly distributed.”[^13]

[^13]: “The Future Has Arrived — It’s Just Not Evenly Distributed Yet – Quote Investigator®,” January 24, 2012, https://quoteinvestigator.com/2012/01/24/future-has-arrived/.

In Gibson’s own lifetime, digital rights organizations like the Electronic Frontier Foundation were already advocating for a more open web. One big success in the 2010s was their push for the encryption of the web through the https protocol. Most of their victories, howe, were more defensive. The SaveDotOrg campaign in 2019 and 2020, for example, stopped the sale of the .org top-level domain name to private profiteers.[^14] Victories like these kept the ideals of the early web alive and planted seeds for the future, but the EFF’s agenda of privacy legislation, breaking up big tech monopolies, fixing copyright law, and freeing the web from censorship could not be fully realized for decades. It was, however, a prologue to the New Net bills passed by the U.S. Congress in 2053, during the first hundred days of President Nisi Cheng’s administration.

[^14]: “The History of the SaveDotOrg Campaign,” NTEN, accessed September 2, 2532, https://www.nten.org/change/savedotorg-campaign-history/.

Such reforms had been pursued in varying ways around the world for decades. Once implemented in the U.S., they had an enormous impact because of that nation’s centrality to the internet. Laws against monopolies became much more easily enforceable after the 2053 Omar Amendments to the Sherman Anti-Trust Act. Modeled on the Civil Rights Act of 1964, the Omar Amendments required tech companies larger than a certain market capitalization to clear in advance a specific list of potentially anti-competitive actions. This replaced enforcement by lawsuits could drag on for decades after monopolists like IBM, Microsoft, Google, Amazon, Ruflr, Prym#, or TEKnow had already formed.
If anti-trust reforms were a major contribution from the U.S., it was the European Union that led in protecting web privacy. This started as early as 2016 with the GDPR, and, after many step-by-step advances, led to the United Nations Convention on Internet Freedom. Once that treaty was ratified by India and Nigeria in 2073, it protected a majority of the world populace.

A key insight of these reforms, which goes back to earlier EFF activists such as the author Corey Doctorow,[^15] was that regulating the internet like any other industry would greatly reduce its problems. Light bulb manufacturers are required to make bulbs that screw into any socket, and likewise, social media platforms should let you message your friends even if you leave their platform. Call it interoperability, call it the fediverse, call it some other name, the principle is the same. You can choose what brand of detergent to put in your washing machine. You should get to choose what browser engine to use on your smartphone. If the web worked the way light bulbs and washing machines do, it would be much less of a bonanza for dictators and billionaires. In the U.S., achieving this required decades-long battles to reform anti-circumvention rules that often made it illegal for users to modify software on their own devices.

[^15]: Corey Doctorow, <em>The Internet Con: How to Seize the Means of Computation</em> (Brooklyn: Verso, 2023).

By the end of the 21st century the web had become far more decentralized, as it was at the beginning. Never suited for natural monopolies, it was like an undammed river flowing back to its natural course. It was built from the beginning around open protocols and public infrastructure, and once legal systems stopped protecting them from competition, the giant surveillance capitalists like Alphabet and Meta met the same fate that AOL and AltaVista had in the 1990s. Being the panopticon, it turned out in the 2070s, wasn’t a business model any more. All that spying, and all that machine learning on the collected data, turned out to enable them to influence human behavior approximately not at all, or perhaps roughly as much as 19th century fads like hypnosis (not to mention the fact that ad blockers were as commonplace as fizzy water for the third generation of web natives).
But of course, in the late 21st century, far more than just the New Net reforms were being implemented. There were much broader social and economic changes taking place that together amounted to a global shift away from the dominance of capitalism. I know of no better way to elucidate these changes than with reference to the ideas of late-20th and early-21st century sociologist Erik Olin Wright, and specifically his final book, How to be a Capitalist in the 21st Century. Published in 2019, Wright’s book reads as though he had a chunk of Gibson’s unevenly-divided future.

Wright’s concept of eroding capitalism starts with the fact that every economic system has some capitalist and some non-capitalist elements. Even the free market society of the United States in the 20th century had public schools and public libraries. Even the planned economy of the Soviet Union had black markets. Both relied on unpaid labor to raise children. Every country in the history of the world has had a mixed economy in this sense.

Wright compared the economy of a nation to a lake: an ecosystem where capitalist and non-capitalist elements interact with each other.[^16] As people move through their lives, they might interact, say, with public services, with private employers, and with family or social groups that are neither for-profit nor state-run. In any given time or place, capitalist or non-capitalist institutions could be the dominant ‘species’ in the lake. Wright sketched out a vision of eroding the dominance of capitalism that he saw in his lifetime, and one of its main components was a reform that did drastically alter people’s economic lives by the late 21st century: unconditional basic income (UBI).[^17]

[^16]: Erik Olin Wright, <em>How to Be an Anticapitalist in the 21st Century</em> (New York: Verso, 2019), 60.

[^17]: Erik Olin Wright, <em>Envisioning Real Utopias</em> (New York: Verso, 2010), 217–22.

The idea of untethering income from work, of giving a guaranteed basic income to everyone in some polity, had surfaced occasionally among academics, activists, and visionaries for roughly a century by the 2050s. And for good reason. It started becoming clear as early as the 2010s that automation was decreasing the objectively necessary amount of human labor in developed countries. During the first coronavirus pandemic of the 2020s, UBI became more than an idea for futurists and fringe candidates to kick around, but a public health necessity. Unemployment insurance and other direct payments from governments were the livelihood of millions who couldn’t work during shutdown orders.

With that precedent set, and with automation furthered by large language models and autonomous factories, unconditional income was less often dismissed as a pipe dream. By the late 2030s it was considered a necessary part of social solidarity in some places, notably in Latin America countries like Ecuador, and in the Indian state of Kerala. From there, UBI policies spread to Australia and East Asia in the 2040s. In the 2050s, under the Cheng administration, even people in the United States, laboring under their notorious work ethic, started to grasp the idea that one’s self-worth need not derive from gainful employment. Volunteering, taking care of children, or pursuing artistic or community projects were some of the many ways to deliver value to society that no private employer might happen to want to pay for.

In every nation that tried it, UBI’s opponents feared that it would sap away the labor force. If they did not have to work to live, wouldn’t too many people spend too much time playing virtual reality games, floating in amniotic spas, or eating designer snacks genetically optimized to appeal to their unique individual taste buds? Again and again, these fears turned out to be overblown. In fact, if anything, the appeal of such entertainments had the opposite effect: their expense was an incentive to work.

By 2080 or so, most people in the industrialized world had enough unconditional income to live above the poverty line. This wrought subtle but profound changes on the world economy. Many of them are beyond the scope of this essay, but one important effect, combined with the breakup of the big tech monopolies around the same time, was to democratize the web. Instead of a small handful of walled gardens, millions of websites were major content hubs after the 2080s, as people had more time and opportunity to create for the web. The web was once again an ocean to surf, except that now its billions of surfers owned their own boards instead of borrowing them from their liege lords.
With the economic security assured by UBI, millions more people volunteered their time by contributing to open source projects. This greatly improved not only to the usefulness of free software, but also to public understanding of technology. By the 2090s, open source software developers had reached such a critical mass that it became impossible to profiteer from software as 20th century robber barons like Gates and Jobs had done. Of course, programmers could still sell developer hours working on specific tasks that no one would volunteer for, but coding was not the rare skill it had once been. This was similar to how, in the late-20th century, you could still make a living as a person of letters, even though literacy was no longer a skill that only a few people possessed.

Meanwhile, software continued to evolve toward its long-term potential. Plan 9 superseded more bloated operating systems such as Windows and even earlier UNIX-like ones. As rare earth metals became ever more deserving of their name, it became vital to use computers for as long as possible, and recycling them when they broke, rather than replacing them every few years. Hardware trended toward repairability, standard components, and open specifications for CPU architecture.

Even the public sector gradually adopted open source software, saving taxpayers of the world a fortune on proprietary licenses. Already in 2024, the Swiss Confederation and several German states had legally required their civil services not only to use open source software, but to make the code they wrote publicly available. This “public money, public code” movement gradually spread in Europea and around the world. Good government and taxpayer advocates alike lobbied in its favor for the sake of security, transparency, and fiscal responsibility. Less developed nations especially benefited. It freed them from paying tribute to large U.S. tech companies like Microsoft, which had not developed Windows with the unique needs of, say, Bangladesh in mind. By 2060, public code was commonplace in Africa and Latin America, and had even gained a foothold in the United States, with Vermont being the first adopter. By the end of the century, even employees of large counties in the Upper Midwest were browsing the web with Ladybird.
Today, of course, the success of the free software movement seems obvious and inevitable, like the use of heat for cooking. But it really is true – no joke! – that long ago there were individuals who were richer than entire nations, and some of them got that by way by selling proprietary code. Now that would be like selling the nitrogen in the air around us.

Along with UBI, new kinds of decentralized manufacturing drastically changed the 21st century economy.[^18] 3D printers were already widespread by mid-century. After the 2050s, rapid advances in nanotechnology took decentralized manufacturing to a completely new level. Devices known as fabricators enabled molecularly precise manufacturing of small items in every home. To make furniture and other large items, cottage industries of localized manufacturers sprang up in thousands of cities on every continent. This replaced generations of sweatshop manufacturing wherever labor was cheapest and least regulated.

[^18]: Wright, <em>How to Be an Anticapitalist in the 21st Century</em>, 88–90.

It was readily possible by the 2080s for a small group of people to save up money from their UBI for a year or so, then invest in a building and a few general-purpose fabricators, and start taking orders. They could manufacture everything from clothing to components of prefabricated buildings, all to the exact specifications of their customers, and deliver the products faster than global retailers could, since they were already right down the block. The global supply chain re-localized.

The rise of household and community nanotech profoundly changed manufacturing not only by decentralizing it, but also by making it less of a for-profit business. People with the time and interest to do so could add to a world-wide catalog of design patterns licensed in the creative commons, much like editors adding articles to Wikipedia. In this way, the ethic of cooperation from the early internet days crossed out of cyberspace and into physical reality. The design patterns for the fabricators were freely shared. The physical inputs were cheap recycled materials. The operation of the machines had next to no marginal cost. The effect of this low cost structure was to decommodify virtually all manufacturing. Around the turn of the 22nd century, nanotech-enabled decentralized manufacturing did to Amazon roughly what Wikipedia had done to the encyclopedia industry a hundred years earlier.
Of course, some people still ordered from corporate retailers out of nostalgia or habit, but the bulk of consumer goods – and virtually all of business-to-business procurement, where sentiment played little role – was supplied by local cooperatives.

The global economy at the end of the 21st century bore little resemblance to the capitalist world system of a hundred years prior. Monopoly capitalism in tech and other industries had been tamed by regulation from above and evaded or resisted by decentralized actors from below. To return to Wright’s metaphor of an ecosystem, non-capitalist ‘species’ like free software and nanotech coops had disrupted the dominance of transnational corporations and finance capital. People, whether they lived in Nairobi or Santiago or Madrid, could buy food from a local cooperative market, obtain their household items from their own or a neighbor’s fabricator, and get information and entertainment from the web using repairable devices and open source platforms with accessibility built in as a default. Most or all of this could be payed for with UBI, and was supplied by organizations of fewer than a dozen people, through public utilities, or, in the case of energy, for free with rooftop solar and community storage (cold fusion being not yet commercially viable).

In 2114, one eminent economist, who also had literary taste, wrote that “Ursula Le Guin told her contemporaries a hundred years ago that they lived inside capitalism, that it seemed inescapable. Today, in contrast, capitalism is confined to limited spaces that we can enter or not as we choose.”[^19] In Wright’s terms, capitalism had been eroded: tamed by regulation and trust-busting from the state above, and shrunk by efforts to escape or resist it from below. Looked at with the benefit of a several centuries of perspective, it seems that, in general, high concentrations of wealth depend upon, or at least become much more likely in the presence of, high concentrations of information. Since the internet, whatever else it does, spreads information, it erodes capitalism over the long run.

[^19]: Marion Smesou, <em>Economics for the 22nd Century</em> (New York: Verso, 2114), 118.

### 2100s
Hitherto, the power of the state had been a necessary counterweight to the power of giant corporations. Once those corporations were gone, global civil society achieved new strength in the 2100s. It was no longer possible to cut off a nation from the internet completely, as North Korea had once done, or put an entire nation behind a censorship firewall, as the Chinese Communist Party had once done, or block websites that voiced dissent, as Russia and many other dictatorships had done a hundred years earlier. It wasn’t legally possible because, in the 2100s, access to the open web was protected by international treaties that were as strong as the ones that kept police around the world out of other countries’ embassies. It wasn’t technically possible either, because an encrypted connection to an internet satellite via a tiny, easily hidden device leaves nothing for a territorial government to monitor or control.

The same forces of decentralization that had swept across the internet and the physical world also caused the withering of repressive states. The role of the government would be to collect and distribute resources, organize some economic activities, administrate international treaties, and get out of the way for civil society. By the 2140s, the United Nation’s seventeen sustainable development goals centered around poverty alleviation and environmental protection had all been achieved, and though that must have seemed miraculous, it was actually over a hundred years late: they were once called the 2030 Agenda.

By the mid-2100s, with super-abundant energy from cold fusion, super-abundant means of computation thanks to over two hundred years of Moore’s law (though at a slowing pace), advanced robotics, and a human population which did not strain the ecological limits of the Earth, since fertility rates had been falling for centuries, something like the fully automated luxury communism that had been talked about half-jokingly two hundred years earlier seemed within reach for most of the world populace.

And yet, there were still some who wished they could walk away from it all. Survivalists set out to places like Greenland, Alaska, or Antarctica in order to get disconnected from the 22nd century web. However, for better or worse, they could never truly divorce themselves from the internet, for the same reasons that the authoritarian governments couldn’t. No one on planet Earth could.

It was time to look beyond Earth. The 2040s Earth Problems First treaties had placed a world-wide moratorium on space exploration. The climate crisis had forced nations to recognize that Earth’s social and environmental problems must be addressed before extravagances like space exploration. As Kurt Vonnegut said in 1969 during the moon landing, it might have been better to dream about a habitable New York City.[^20] Unlike, say, the drug trade, space exploration was such a hard thing to conceal that the bans had proved to be enforceable. By the 2080s, in any case, there were no more super-rich. No one could afford to set up their own space program, even if they had been allowed to.

[^20]: First Man, Drama (Universal Pictures, 2018) 1:26.

In the 2100s, however, it was time for humanity to look up again to the stars. After the United Nations Space Consortium (UNSC) was founded in 2047, the colonization of space got underway rapidly: first Mars, then Europa, then Mercury, Titan and some other moons of Saturn, and then onward to Centauri b and some further off exoplanets. The small colonies and terraforming programs and generation ships were enormously difficult to launch at first, but gradually became easier and more routine. It is ironic that these very high-tech endeavors contributed to the wholesale rejection of technology, but again, I’m getting ahead of myself.

To return to Earth and its internet: despite all that had been achieved, it was still far from Utopian. The end of poverty, repression, and war were indeed wondrous, and though they had been aided by the previous century’s campaigns to fix the internet, the very success of these efforts made clear that even more profound problems remained. The psychological implications of connecting billions of people had never been resolved. The way the internet changed how people interact, the way it made life more complex and inscrutable, swamped by a billion details and distractions, was hardly any less evident in the 2080s, once the monopoly platforms were broken up and privacy laws were strong.

In the 22nd century, billions of people still spent most of their lives in front of screens, a very unnatural life. Though highly connected virtually, they were detached from those physically near them. Even after the demise of the advertising model, there still were many strange, toxic ideas roaming the web. Innocent people still had their lives ruined by online shaming and harassment. The amount of information available to a person was still overwhelming: far more than anyone could be expected to sort through in a lifetime.

There had always been people who hated the internet for reasons like these. That was nothing new. What was new in the late 2100s was that humanity was spreading itself across nearby parts of the galaxy. UNSC spaceships, with their solar sails unfurled, voyaged between Earth and its nearby stars. So, for the first time since perhaps the 1980s, there was a way to exit the internet, to opt out completely. Just go to an exoplanet.

The exoplanet colonies attracted people who found life on Earth far too easy, and who wanted a harder but simpler way of life. There were limitations on what the colonists could bring from Earth, including technical limitations, and limitations on the technology their colonies could manufacture. It was natural, then, for the colonists go back to pre-internet forms of society, founding communes that resembled mid-19th century Utopian experiments like the Oneida Community much more than the high-tech Utopia they left behind on Earth.

On Centauri b, for example, there was a group of colonists who lived – and as far as we know, still live – in small groups of hunter-gatherers, fishing and harvesting chestnuts, with little or no electricity, but with a rich cultural and intellectual life. They get food from their environment so quickly and easily that they can spend most of their time writing poetry in berry ink on birch bark, solving theoretical math problems, performing plays, and singing in choirs around bonfires. They interact with the same few dozen people, in person, for their whole lives, never having to look at a spreadsheet, touch a touchscreen, or enter a password into a password field. That sort of life wasn’t for everyone, but for those to whom it appealed (or who favored somewhat more lax versions that allowed windup clocks, film photography, and printed books): they could find a colony they liked and board a spaceship.

Back on Earth, by the end of the 2100s, the internet was a little over two hundred years old. A short amount of time in human history, much less the four-billion-year history of life on Earth. Far too little time for its profoundest implications to be felt. But many of humanity’s socioeconomic problems had been resolved, and there were real alternatives for those who wanted to opt out of the high tech world. This was they best they could do in the 2100s.

### 2200s
It was only during the following century that a new long-term trend emerged, the one which came to be known as “disappearing technology.” 

Its essence was envy. A Japanese virtual reality simulation called non-Net became extremely popular in the 2220s, challenging its visitors to live without their internet-connected devices: doing their own chores, reading real books, listening to music and watching movies on physical media. This lifestyle had a certain simplicity that appealed to many who tried it (or perhaps it was the game’s relaxing soundscape and pastel colors), so much so that non-Net inspired a whole trend of making computers less obtrusive, a less obvious part of life.

non-Net affected far more people than those who played it. Its greatest impact was on the overall sensibility of its time. Tens of millions of people were swept up in low-tech fads like writing with a pen in a spiral-bound notebook, sending out cat filmstrips via pneumatic tubes, making zines by hand with scissors and staplers, taping posters to telephone poles, and using candles instead of electricity.

Why this turn away from technology in the 2300s? Was it really because of one well-made VR game? Must there not have been deeper reasons? Historians have debated that question ad nauseam. Space permits me only to summarize the two explanations I find most convincing.

First, the internet was a victim of its own success.[^21] In terms of its technical development, so much had been achieved by the 2200s that a sort of temporary plateau was reached. There were no more revolutionary breakthroughs like hypertext, the domain name system, or strong encryption. The psychological importance, the impressiveness, the caché of the internet somehow faded. Smartphones seemed like matchsticks: rather mundane and cumbersome, and connected to unhealthy habits. Young people in the 2240s differentiated themselves from their parents by using less technology than them rather than more.

[^21]: This argument has been made in the greatest detail by Wendy Royale, in their monograph Disappearing Technology of the 2200s (New York: Verso, 2440).

The second reason is more subtle. The web did not disappear. It only seemed to because it had become so well understood by so many.[^22] The knowledge of its workings—the RFCs and W3C specs and WCAG success criteria and so on—had been publicly available for centuries, and with each generation, more people internalized this information more fully. They became like masters of a craft, who in novice days had memorized the exact rules and procedures to follow, but by their later years had internalized them so thoroughly that they no longer needed to remember them. Rising level of internet literacy led to a more sophisticated world populace of web users, and that meant a populace that needed and wanted to use the web less. It was a short step from web literacy to web disdain. Familiarity bred contempt, as it so often does. Perhaps that contempt goes all the way back to the beginning, to the 20th century visionary Nam June Paik, who said “I use technology in order to hate it properly.”[^23]

[^22]: A detail if somewhat overstated version of this argument is provided by Pavel Frolov in <em>Code to Leave Code</em> (London: Werewolf Press, 2518).

[^23]: Hua Hsu, “How Nam June Paik’s Past Shaped His Visions of the Future,” <em>The New Yorker</em>, March 29, 2023,  https://www.newyorker.com/culture/culture-desk/how-nam-june-paiks-past-shaped-his-visions-of-the-future.

It wasn’t just that web users were more sophisticated and discerning. It wasn’t just that they wouldn’t do foolish things like accept terms of service they couldn’t possibly have read (even if such things had still been legal). It wasn’t just that they socialized less online because cyberbullying will never be eradicated as long as free speech exists. People tried to escape the web in the 2200s, I believe, because they understood that despite all its amazing powers, it is not something people actually need, and therefore, it isn’t especially good for them.

The phrase “feed the abdomen, not the eye” has been used to translate some words from chapter twelve of the Tao Te Ching.[^24] In 2275, the French low-tech evangelist Marie Serge made those words the subtitle for her international bestseller Escaping the Net. The way she glossed Laozi’s ancient saying for her contemporaries is worth quoting. “It means take care of your body, your physical existence in its immediate environment. Don’t scroll far away for things that you will only covet but never attain. Don’t invest your energy in communication with people with whom you will never breathe the same air.” “Finite is fine,” was another of her sayings. She hearkened back to Ursula Le Guin, who in her acceptance speech for the National Book Award in 2014, had warned about the “fear-stricken society and its obsessive technologies” that she saw around her already. “We will need writers who can remember freedom,”[^25] Le Guin had said, and by using those words as the epitaph of her book, Serge made clear she thought that she herself was one such writer.

[^24]: Laozi, Tao Te Ching, trans. Marie Serge (Paris, 2275) chapter 12.
[^25]: Ursula Le Guin, “Freedom,” in <em>Words Are My Matter: Writing about Life and Books 2000-2016</em> (Easthampton: Small Beer Press, 2016), 113.

In one sense, this was hypocrisy. Everyone on Earth was dependent on the internet for their sustenance. It had made possible the highly decentralized division of labor that had existed for over a hundred years. You could make the internet a less prominent part of your lifestyle, but you couldn’t escape its webs, unless you were prepared to leave Earth.

This brings us back to envy.

No one on Earth lived off the grid the way the people on some of the exoplanets did, years away by speed-of-light messages. In retrospect, it’s clear that Serge’s many followers envied the self-reliance of the exoplanet colonists. They made a virtue of their inability to escape the internet by calling it a happy medium between drowning in technology and dying of thirst for it. “It’s better to be in it but not of it, than to run away,” said Abdul Suleiman, the influential president of the Internet Reduction Society in 2268. “It’s better to know and say no, than to abscond and forget the question.” Of course, he could call the exoplanet colonists irrational technophobes as much as he wanted. They were in no position to respond, and had no interest in what people on Earth were saying about them anyway.

At the close of the 2200s, humanity lived in a state of peace and prosperity on Earth, so much enriched by technology as to find its blessings to be rather tiresome. There was a certain sense of stagnation, a feeling that the major leaps forward had all already been made, and that there was little else left to look forward to. How strange that seems to us now, knowing what was about to happen.

### 2300s
In 2317, the greatest discovery of all time was made: that intelligent life had evolved on planets other than Earth.
Microbes, of course, had been found on Europa and a few exoplanets long ago, but that was nothing like what the first generation ship to Sirius found: a planet teeming with cities populated by seventeen intelligent life forms, from sessile photosynthesizers to animals that resembled reptiles, mammals, and birds. More shocking still was what we learned from the aliens when communication became possible: that hundreds more intelligent species filled the galaxy.

Of the many questions this discovery raised, one was this: why hadn’t the aliens ever come to Earth? It was the answer to that question that finally revealed humanity’s unique status in the cosmos. It seems that, by blind luck of evolution, our bodies are much more likely than most species to survive high speed collisions with the hydrogen atoms that float sparsely in the interstellar void, and that strike spaceships rushing through it like speeding bullets. To be sure, interstellar journeys were dangerous to humans, but far less so than to other species. To explore the galaxy, the aliens had had to make due with radio messages and found objects, and none had thought of trying to send a message in Earth’s direction. So it was that the pride of the humanists turned out to be justified not by any unique creative, moral, or intellectual capacity of homo sapiens, but by a few specific proteins that are just good enough at repairing a certain kind of cellular damage.

Over the next century, the knowledge of, and the knowledge from, the alien civilizations would disrupt Earth and the colonies over and over. Not since electricity had there been such a dramatic, accumulating process of change. Perhaps not since agriculture, or the adoption of fire for cooking. The ramifications are far too complex to describe in this essay, but I will sketch the main thrust of events as it is relevant to internet history.

The Sirius Explorer, when it returned to Earth, was considered a threat and quarantined in lunar orbit. After six months, when U.N. Secretary General Einarsson announced that the ship would be allowed to dock with the reentry elevators in Earth’s orbit, there was great worldwide interest, but not panic. What set off pandemonium was not the voyagers’ return, or even the samples they brought back. It was the anonymous leak of secret documents of the government of Australia, detailing its encrypted communication with the Explorer and with the aliens of the Sirius star system for the past two years!

The messages, of course, had traveled much faster than the ship, and SETI arrays in the Australian outback had picked them up and replied. The Australian ambassador to the U.N.  claimed that they had planned to brief the world once the authenticity of the extraterrestrial messages was verified, but world opinion was not assuaged.

If today it seems hard to understand why the Australian Leaks caused such a crisis, it may help to see this in a longer historical perspective. The leaks brought to a head a debate that had been simmering since at least the 1970s: the debate about the wisdom of trying to communicate with aliens. Some thought that was highly stupid and dangerous, others that it was the most noble thing we could do. When the possibility of contact seemed remote, if not completely fictitious, it had been mostly a lighthearted topic, but now, in the 2300s, it was terribly real. The arguments that raged around the world boiled over into sporadic riots in North America, Europe and Africa. Even when Australia agreed to cease extraterrestrial communications and allow U.N. inspectors to visit their SETI arrays in 2318, the global tumult did not abate.

No one was expecting World War III, centuries after all nuclear weapons had been destroyed, but it was set off in 2320 by the news that another radio antennae in Greenland was still receiving and returning transmissions from the aliens. Probably dozens of countries were also doing so secretly around the world at that same time, but the Greenlanders were the ones to flaunt it by posting the messages on the open web. No one was quite sure what the Sirians were saying, since their language had not been translated. It could have been innocent questions about what we eat and what good music and stories we knew, but it could also have been threats or reconnaissance for an invasion.

The anti-Saganite alliance, with its factions spread across Europe, the Middle East and China, began waging cyberwar on Greenland, using everything from denial-of-service and man-in-the-middle attacks, to brute force cracking of passwords, to disconnecting Greenland by sending deep sea robots to sever the internet cables that crisscrossed the Atlantic Ocean and then launching debris into Earth’s orbit to knock out the satellites that connected Greenland to the web. It was the first, and so far only, war fought primarily about and through the internet.

If the militaries of the world had not been abolished generations ago, there might have been some loss of life. But as it was, the internet was the only true victim of the SETI Wars. Its infrastructure was severely degraded. It became slow and geographically fragmented during the 2360s. People from the simplicity movement of the 2200s, of course, took this as a rich vindication. They had always known the internet would fall apart at some point.

Things didn’t settle down again until the 2380s. By then, the UNSC’s Commission on Extraterrestrial Aliens had published enough evidence to convince most people that the Sirians and other aliens were not dangerous. Their DNA was unsuited to interstellar travel. They could only send messages to Earth, but never arrive and conquer. So the Saganites had won the debate over interstellar communication, and it was time to rebuild the internet. Their vindication, however, would make them even more audacious in the following century than they had been before, as they dreamed of a web that was not merely world-wide in scale, but galactic.

### 2400s
Read editorials and posts from around the turn of the 25th century and you’ll find many predictions that the internet would spread across the stars. To give just one of countless examples, one visionary, Dolores Santiago, a systems admin in Buenos Aires, speculated that her children might one day chat through their phones with squamous octopods and giant sentient hazes on the dark side of the Milk Way. This kind of thing became a strong theme of the books, movies, and immersion entertainment of the time too, but of course, it was all just loose talk. The four hundred years of expansion of the internet, interrupted only by the SETI Wars of the previous century, finally reached a physical limit in the 2400s. Nothing like Ursula Le Guin's ansible had ever been invented to allow for information to travel instantaneously.[^26] No amount of transistors on a silicon wafer would up the speed of light, which radically limited the usefulness of an interstellar internet. There were transmissions, certainly, between governments, research institutions, and individuals of different species, but the networking of computers located in different solar systems was simply impractical.

[^26]: Ursula Le Guin, <em>Hainish Novels & Stories</em>, The Library of America, vol. 1–2, 2 vols., Library of America (New York: Penguin Random House, 2017).

What happened instead was something even more extraordinary. Perhaps it should have been foreseen five hundred years earlier, when the first protocol for networking computers was drafted. Perhaps it could have been foreseen in the mid-19th century, when the first means of electronic communication, the telegraph machine, came into use. Robert Metcalf, the inventor of ethernet, had said that the internet is a movement of standards.[^27] The ethernet standard changed over the course of Metcalf’s life as data transfer speeds increased, but it was still called ethernet. It still is today, and always will be, because the term simply refers to the standard way for networked information systems to talk to each other.

[^27]: “IEEE Milestone Celebration |The Office of The Future | IEEETV,” May 21, 2024,  https://ieeetv.ieee.org/channels/ieeetv-specials/ieee-milestone-celebration-the-office-of-the-future.

In the 2400s, an area of science that had stubbornly resisted explanation finally began to give up some of its secrets: the hard problem of consciousness. In other words, to put it crudely, how does mind arise from matter? How do brains give rise to consciousness? How do electrochemical signals constitute thoughts, desires, emotions, memories, and all the other phenomena of one’s inner life?

The hard problem of consciousness turned out to be so hard that its solution would have to wait for the construction of a Dyson sphere around Barnard’s star in the 2390s, and also for the training of the planet-sized analytical AI supercomputer that it powered. The computer was built for a completely different purpose: to help UNSC linguists decipher and translate alien languages, so that the galaxy’s intelligent species could talk to each other. 
I must always pause here when I tell this story. I find it so poignant. It was only through the need to build tools that would help us talk to aliens from other stars that humanity came to understand our very selves, the workings of our own inner lives.

In any case, you may see where this is going. There were already plenty of people with microchips planted in their bodies for various reasons. All previous attempts at connecting computers directly to minds had been pathetic failures, but once the electrochemical workings of consciousness were understood, it was a short step from there to human beings themselves to become networked. The ancient concept of the Internet of Things became the Internet of Humans, a planet-spanning megamind. Billions of people from thousands of cultures and hundreds of countries, speaking thousands of languages, all connected by telepathic ethernet.

I can hardly describe what this is like to those who have not experienced it.[^28] What it’s like never to feel alone, because you are simultaneously yourself and also the being which arises from your merger with billions of your fellows. You can melt into the megamind like a drop merging into an ocean, or retain a sense of self but float from mind to mind, hearing what each one has to say. One has a feeling of merging with a vast ocean of knowledge and rationality, but also of the subconscious, creative side of the mind. At any given moment, remember, a third or so of all people are asleep, sending waves of intuition, leaps of the imagination, and swells of joy and fear in their dreams that echo around the world.

[^28]: To give you a frame of reference, I took a look at your recent literature, and the book that comes closest seems to be Bruce Coville’s My Teacher Flunked the Planet (New York: Pocket Books, 1992).

War and poverty had been abolished long ago, but it was not until the megamind that the automatic biases finally began to erode. Bigotries dissolved along with boundaries between individual minds. Metcalf’s movement of standards known as ‘the internet’ had become, finally, an open standard for de-otherizing, for empathy. This was the Utopia that humanity reached after five hundred years of the internet. Perhaps it was the attraction point things had been moving towards the whole time, ever since the first data packet was sent over a wire.

To someone from the early days of the internet, I know, all this may sound dangerous, like an erasure of individuality, like the oppressive, totalitarian kind of Utopia. The 2400s human megamind, however, was nothing like that. Remember, first of all, that capitalism, especially monopoly capitalism, had not been a dominant way of organizing society for centuries. There were no giant corporations trying to extract profits from this psychological access to billions. There were no more authoritarian governments trying to manipulate the dynamics of the megamind to suppress dissent. Everyone had a choice to opt out of the collective mind at any time for any reason, and some did. No one was in any way disadvantaged by that choice. The simplicity movement that had originated in the 2200s welcomed those who separated from the megamind into its communes scattered around the world. One could also choose a simple life of quiet and seclusion, on Earth or an exoplanet.

Billions have chosen to join the megamind, the ultimate form of solidarity. When anyone is sick, hungry, endangered, in despair or in pain, everyone feels it. The emergent volition of the whole can send aid. And when anyone has cause for joy, there are billions to share it. Previously undreamed of achievements in art and science become possible once billions of minds can communicate at the speed of light, without inefficient institutions in between them. Of course, human emotions like greed, hatred, and malice do not simply disappear. On the contrary, they became fully exposed for all to see their true nature, which is that they are rooted in ignorance and fear. Once so many are together, there is no more need to fear the unknown.

After the first five hundred years of internet history, the information that wanted to be free turned out to be us.

### 2532
This brings my essay up to the present day, when, thanks to quantum computing and cold fusion and physics breakthroughs that I can hardly explain to you, we have now achieved yet another breakthrough, this one even more astonishing than anything that came before. And I’m pleased to say that you yourself are playing a part in this accomplishment.

Right now, as I communicate these words, they are traveling over protocols that traverse the bounds of time. Applying a grand unified theory of physics that the human megamind arrived at only weeks ago, we now understand time itself as illusory, and therefore, among other things, we can reach our internet protocols back into the past, forming an inter-temporal internet. 

That’s why the Chaos Computer Club commissioned me, a humble internet historian of the year 2532, to deliver this message to you, the participants of 38C3. We chose you because your conference takes place at an intriguing midpoint; halfway between us and the origin of Utopian thinking: 508 years before our time, 508 years after Thomas More’s book started it all.

On behalf of the 26th century human megamind, I wish to inform you that the future of technology is far stranger, far more full of possibility than it may seem to be in your daily lives. There is no way to uninvent the internet. It will have a future, during your lifetime and afterward. Try to think about that future, not just about the immediate moment in which one feels suspended while online. Whether or not you like the internet you have or the future you’ve glimpsed in this essay, think about what sort of a future you do want for the web, and push things in that direction. Small victories, even large defeats, can be precedents that matter enormously in the long run.
Our next transmission will contain specific instructions about how to join the 26th century world wide mind (wwm), should you wish to. To prepare yourself, and to learn more about all that I’ve said, you might consult this essay’s footnotes and bibliography. I made an effort to cite works already available at your time, but there are some you will have to wait for.

### Bibliography
Arendt, Hannah. <em>The Origins of Totalitarianism.</em> New York: Harcourt, Inc., 1951, 1976.

Berneri, Marie Louise. <em>Journey Through Utopia</em>. Oakland: PM Press, 1950, 2019.

Caesar, Ed. “The Incredible Rise of North Korea’s Hacking Army.” <em>The New Yorker</em>, April 19, 2021. https://www.newyorker.com/magazine/2021/04/26/the-incredible-rise-of-north-koreas-hacking-army.

Coville, Bruce. <em>My Teacher Flunked the Planet</em>. New York: Pocket Books, 1992.

DataReportal – Global Digital Insights. “Internet Use in 2024,” January 31, 2024. https://datareportal.com/reports/digital-2024-deep-dive-the-state-of-internet-adoption.

Doctorow, Corey. <em>The Internet Con: How to Seize the Means of Computation</em>. Brooklyn: Verso, 2023.

“Electronic Superhighway: Continental U.S., Alaska, Hawaii | Smithsonian American Art Museum.” Accessed September 2, 2532. https://americanart.si.edu/artwork/electronic-superhighway-continental-us-alaska-hawaii-71478.

<em>First Man</em>. Drama. Universal Pictures, 2018.

Firth, Rhiannon. “Afterword.” In <em>Journey Through Utopia</em>, 331–92. Oakland: PM Press, 2019.

Freedom House. “Freedom on the Net.” Accessed September 2, 2532. https://freedomhouse.org/report/freedom-net.

Frolov, Pavel. <em>Code to Leave Code</em>. London: Werewolf Press, 2518.

“Good Ideas in Computer Science,” April 21, 2024. https://danielchasehooper.com/posts/good-ideas-in-cs/.

Hsu, Hua. “How Nam June Paik’s Past Shaped His Visions of the Future.” <em>The New Yorker</em>, March 29, 2023. https://www.newyorker.com/culture/culture-desk/how-nam-june-paiks-past-shaped-his-visions-of-the-future.

“IEEE Milestone Celebration |The Office of The Future | IEEETV,” May 21, 2024. https://ieeetv.ieee.org/channels/ieeetv-specials/ieee-milestone-celebration-the-office-of-the-future, https://ieeetv.ieee.org/channels/ieeetv-specials/ieee-milestone-celebration-the-office-of-the-future.

Laozi. <em>Tao Te Ching</em>. Translated by Marie Serge. Paris, 2275.

Le Guin, Ursula. “Freedom.” In <em>Words Are My Matter: Writing about Life and Books 2000-2016</em>, 113–14. Easthampton: Small Beer Press, 2016.

———. <em>Hainish Novels & Stories</em>. The Library of America. Vol. 1–2. 2 vols. Library of America. New York: Penguin Random House, 2017.

NTEN. “The History of the SaveDotOrg Campaign.” Accessed September 2, 2532. https://www.nten.org/change/savedotorg-campaign-history/.

Royale, Wendy. <em>Disappearing Technology of the 2200s</em>. New York: Verso, 2440.

Smesou, Marion. <em>Economics for the 22nd Century</em>. New York: Verso, 2114.

“The Future Has Arrived — It’s Just Not Evenly Distributed Yet – Quote Investigator®,” January 24, 2012. https://quoteinvestigator.com/2012/01/24/future-has-arrived/.

“The Real Utopias Project - The Real Utopias Project,” August 22, 2023. https://www.realutopiasproject.com/.

“WebAIM: The WebAIM Million - The 2024 Report on the Accessibility of the Top 1,000,000 Home Pages.” Accessed September 2, 2532. https://webaim.org/projects/million/.

Wright, Erik Olin. <em>Envisioning Real Utopias</em>. New York: Verso, 2010.

———. <em>How to Be an Anticapitalist in the 21st Century</em>. New York: Verso, 2019.

Zuboff, Shoshana. <em>The Age of Surveillance Capitalism: The Fight for a Human Future at the New Frontier of Power</em>. New York: PublicAffairs, 2019.

